{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:\\\\Nippun\\\\Desktop\\\\CadUsdDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = data[[\"Norm_Gold\", \"Norm_Oil\", \"Norm AVG_TSX\", \"AVG Price\"]][0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Norm_Gold  Norm_Oil  Norm AVG_TSX  AVG Price\n",
      "0       0.4458    0.4909      0.000000    0.73890\n",
      "1       0.8192    0.4962      0.032840    0.74450\n",
      "2       0.4393    0.5130      0.063791    0.74985\n",
      "3       0.3766    0.5137      0.109089    0.75265\n",
      "4       0.4196    0.5434      0.143644    0.75520\n",
      "5       0.4383    0.6974      0.171673    0.75630\n",
      "6       0.4364    0.6189      0.207663    0.75465\n",
      "7       0.3991    0.3460      0.226961    0.75325\n",
      "8       0.4579    0.2462      0.249321    0.75325\n",
      "9       0.4047    0.4444      0.282791    0.75410\n",
      "10      0.4364    0.5419      0.295931    0.75380\n",
      "11      0.4561    0.4017      0.334895    0.75370\n",
      "12      0.3140    0.5183      0.373964    0.75325\n",
      "13      0.0033    0.5701      0.370692    0.75060\n",
      "14      0.4234    0.3110      0.366371    0.74925\n",
      "15      0.7575    0.2813      0.353284    0.74935\n",
      "16      0.3879    0.4474      0.366318    0.75280\n",
      "17      0.5495    0.4863      0.381645    0.75535\n",
      "18      0.6411    0.3178      0.392930    0.75395\n",
      "19      0.5234    0.3758      0.428675    0.75710\n",
      "20      0.4757    0.5755      0.444894    0.76130\n",
      "21      0.5112    0.4413      0.456949    0.76270\n",
      "22      0.4813    0.4832      0.460448    0.76305\n",
      "23      0.3664    0.4634      0.472608    0.76235\n",
      "24      0.3963    0.2828      0.499290    0.75935\n",
      "25      0.3766    0.3628      0.510802    0.75420\n",
      "26      0.3710    0.3270      0.505273    0.75235\n",
      "27      0.4570    0.3064      0.498782    0.75240\n",
      "28      0.3972    0.3872      0.492624    0.75355\n",
      "29      0.3748    0.4337      0.495895    0.75490\n",
      "..         ...       ...           ...        ...\n",
      "170     0.1355    0.5846      0.802499    0.75760\n",
      "171     0.0000    0.4245      0.814169    0.75930\n",
      "172     0.2850    0.5229      0.800365    0.75990\n",
      "173     0.2673    0.4718      0.800365    0.75920\n",
      "174     0.3458    0.2447      0.827798    0.75750\n",
      "175     0.4963    0.2287      0.847849    0.75485\n",
      "176     0.3850    0.3361      0.862232    0.75405\n",
      "177     0.4579    1.0000      0.872467    0.75520\n",
      "178     0.5495    0.7470      0.893147    0.75385\n",
      "179     0.4598    0.0396      0.909121    0.75335\n",
      "180     0.3523    0.3125      0.921771    0.75405\n",
      "181     0.4131    0.4032      0.928857    0.75405\n",
      "182     0.6561    0.4436      0.925463    0.75460\n",
      "183     0.6542    0.3438      0.908124    0.75445\n",
      "184     0.2402    0.2409      0.892500    0.75370\n",
      "185     0.1860    0.3377      0.892220    0.75435\n",
      "186     0.3645    0.3605      0.870979    0.75510\n",
      "187     0.0243    0.2264      0.855967    0.75580\n",
      "188     0.2570    0.2302      0.809620    0.75350\n",
      "189     0.7467    0.2957      0.739950    0.75020\n",
      "190     0.6514    0.3155      0.737343    0.75040\n",
      "191     0.4664    0.4177      0.761016    0.75120\n",
      "192     0.3318    0.4276      0.757446    0.75090\n",
      "193     0.3355    0.3910      0.744604    0.75020\n",
      "194     0.4981    0.3925      0.746161    0.75115\n",
      "195     0.3916    0.4748      0.770638    0.75500\n",
      "196     0.1944    0.5655      0.780839    0.75765\n",
      "197     0.2570    0.3483      0.771723    0.75750\n",
      "198     0.4692    0.3026      0.774663    0.75930\n",
      "199     0.5579    0.4901      0.777742    0.76155\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        ]\n",
      " [0.97674419]\n",
      " [0.73953488]\n",
      " [0.71627907]\n",
      " [0.58139535]\n",
      " [0.3255814 ]\n",
      " [0.34883721]\n",
      " [0.47906977]\n",
      " [0.55813953]\n",
      " [0.45116279]\n",
      " [0.46976744]\n",
      " [0.4372093 ]\n",
      " [0.23255814]\n",
      " [0.35348837]\n",
      " [0.48837209]\n",
      " [0.8       ]\n",
      " [0.71627907]\n",
      " [0.34883721]\n",
      " [0.77209302]\n",
      " [0.86976744]\n",
      " [0.60930233]\n",
      " [0.51162791]\n",
      " [0.41395349]\n",
      " [0.2       ]\n",
      " [0.        ]\n",
      " [0.30697674]\n",
      " [0.48372093]\n",
      " [0.58604651]\n",
      " [0.60465116]\n",
      " [0.33488372]\n",
      " [0.50697674]\n",
      " [0.70232558]\n",
      " [0.66511628]\n",
      " [0.41860465]\n",
      " [0.58139535]\n",
      " [0.58604651]\n",
      " [0.39069767]\n",
      " [0.56744186]\n",
      " [0.48372093]\n",
      " [0.11162791]\n",
      " [0.12093023]\n",
      " [0.34418605]\n",
      " [0.11627907]\n",
      " [0.2       ]\n",
      " [0.54883721]\n",
      " [0.6372093 ]\n",
      " [0.64186047]\n",
      " [0.70697674]\n",
      " [0.5255814 ]\n",
      " [0.40930233]\n",
      " [0.48372093]\n",
      " [0.51162791]\n",
      " [0.55348837]\n",
      " [0.37674419]\n",
      " [0.15813953]\n",
      " [0.3627907 ]\n",
      " [0.59069767]\n",
      " [0.46511628]\n",
      " [0.33953488]\n",
      " [0.64651163]\n",
      " [0.81860465]\n",
      " [0.50232558]\n",
      " [0.38139535]\n",
      " [0.41860465]\n",
      " [0.37674419]\n",
      " [0.59534884]\n",
      " [0.62790698]\n",
      " [0.46511628]\n",
      " [0.3255814 ]\n",
      " [0.47906977]\n",
      " [0.53953488]\n",
      " [0.4       ]\n",
      " [0.53953488]\n",
      " [0.41395349]\n",
      " [0.46511628]\n",
      " [0.35813953]\n",
      " [0.10232558]\n",
      " [0.32093023]\n",
      " [0.57209302]\n",
      " [0.54418605]\n",
      " [0.66046512]\n",
      " [0.52093023]\n",
      " [0.24651163]\n",
      " [0.53488372]\n",
      " [0.54883721]\n",
      " [0.34418605]\n",
      " [0.4       ]\n",
      " [0.46511628]\n",
      " [0.65116279]\n",
      " [0.48372093]\n",
      " [0.35348837]\n",
      " [0.58139535]\n",
      " [0.47906977]\n",
      " [0.42790698]\n",
      " [0.61860465]\n",
      " [0.54883721]\n",
      " [0.30697674]\n",
      " [0.45581395]\n",
      " [0.55813953]\n",
      " [0.34418605]\n",
      " [0.27906977]\n",
      " [0.46046512]\n",
      " [0.49767442]\n",
      " [0.64186047]\n",
      " [0.79069767]\n",
      " [0.53023256]\n",
      " [0.55813953]\n",
      " [0.86976744]\n",
      " [0.73023256]\n",
      " [0.44186047]\n",
      " [0.2744186 ]\n",
      " [0.35813953]\n",
      " [0.30232558]\n",
      " [0.26046512]\n",
      " [0.56744186]\n",
      " [0.81860465]\n",
      " [0.97674419]\n",
      " [0.62790698]\n",
      " [0.50697674]\n",
      " [0.63255814]\n",
      " [0.61860465]\n",
      " [0.6744186 ]\n",
      " [0.57209302]\n",
      " [0.45116279]\n",
      " [0.57674419]\n",
      " [0.61860465]\n",
      " [0.40930233]\n",
      " [0.36744186]\n",
      " [0.35813953]\n",
      " [0.51162791]\n",
      " [0.61860465]\n",
      " [0.61860465]\n",
      " [0.54883721]\n",
      " [0.3255814 ]\n",
      " [0.47906977]\n",
      " [0.64651163]\n",
      " [0.44651163]\n",
      " [0.22325581]\n",
      " [0.28372093]\n",
      " [0.41860465]\n",
      " [0.4       ]\n",
      " [0.41395349]\n",
      " [0.47906977]\n",
      " [0.53023256]\n",
      " [0.40465116]\n",
      " [0.30697674]\n",
      " [0.4372093 ]\n",
      " [0.29767442]\n",
      " [0.22790698]\n",
      " [0.62325581]\n",
      " [0.6744186 ]\n",
      " [0.44186047]\n",
      " [0.48837209]\n",
      " [0.26976744]\n",
      " [0.25116279]\n",
      " [0.60465116]\n",
      " [0.44186047]\n",
      " [0.3627907 ]\n",
      " [0.56744186]\n",
      " [0.51162791]\n",
      " [0.50232558]\n",
      " [0.60465116]\n",
      " [0.47906977]\n",
      " [0.34418605]\n",
      " [0.46976744]\n",
      " [0.46511628]\n",
      " [0.35348837]\n",
      " [0.71162791]\n",
      " [0.75813953]\n",
      " [0.61860465]\n",
      " [0.6372093 ]\n",
      " [0.53488372]\n",
      " [0.41395349]\n",
      " [0.32093023]\n",
      " [0.23255814]\n",
      " [0.40465116]\n",
      " [0.58604651]\n",
      " [0.35348837]\n",
      " [0.43255814]\n",
      " [0.54418605]\n",
      " [0.47906977]\n",
      " [0.53023256]\n",
      " [0.46511628]\n",
      " [0.40930233]\n",
      " [0.53953488]\n",
      " [0.54883721]\n",
      " [0.54418605]\n",
      " [0.26511628]\n",
      " [0.17209302]\n",
      " [0.49767442]\n",
      " [0.55348837]\n",
      " [0.45116279]\n",
      " [0.41395349]\n",
      " [0.56744186]\n",
      " [0.8372093 ]\n",
      " [0.7255814 ]\n",
      " [0.46511628]\n",
      " [0.64651163]\n",
      " [0.68837209]\n",
      " [0.61395349]\n",
      " [0.56744186]\n",
      " [0.53023256]\n",
      " [0.53953488]\n",
      " [0.51162791]\n",
      " [0.5255814 ]\n",
      " [0.39534884]\n",
      " [0.19534884]\n",
      " [0.27906977]\n",
      " [0.53488372]\n",
      " [0.50697674]\n",
      " [0.42790698]\n",
      " [0.39534884]\n",
      " [0.43255814]\n",
      " [0.35813953]\n",
      " [0.33023256]\n",
      " [0.46511628]\n",
      " [0.42325581]\n",
      " [0.4372093 ]\n",
      " [0.54883721]\n",
      " [0.59069767]\n",
      " [0.3627907 ]\n",
      " [0.22325581]\n",
      " [0.43255814]\n",
      " [0.48372093]\n",
      " [0.44186047]\n",
      " [0.55813953]\n",
      " [0.53023256]\n",
      " [0.45581395]\n",
      " [0.48837209]\n",
      " [0.40930233]]\n"
     ]
    }
   ],
   "source": [
    "output = np.array(data[\"CHG Price\"])\n",
    "output = np.reshape(output, (len(output), 1))\n",
    "max_out = np.max(output)\n",
    "min_out = np.min(output)\n",
    "output = (output - min_out)/ (max_out - min_out)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = output[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = data[[\"Norm_Gold\", \"Norm_Oil\", \"Norm AVG_TSX\", \"AVG Price\"]][200:230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = output[200:230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network :\n",
    "    def __init__(self):\n",
    "        #parameters\n",
    "        self.inputSize = 4\n",
    "        self.outputSize = 1\n",
    "        self.hidden1Size = 2\n",
    "        self.hidden2Size = 3\n",
    "        self.c = 0.15\n",
    "        \n",
    "        #weights\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hidden1Size) \n",
    "        self.W2 = np.random.randn(self.hidden1Size, self.hidden2Size) \n",
    "        self.W3 = np.random.randn(self.hidden2Size, self.outputSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        #forward propagation through our network\n",
    "        self.net1 = np.dot(X, self.W1) \n",
    "        self.fnet1 = self.sigmoid(self.net1) \n",
    "        self.net2 = np.dot(self.fnet1, self.W2) \n",
    "        self.fnet2 = self.sigmoid(self.net2)\n",
    "        self.net3 = np.dot(self.fnet2, self.W3)\n",
    "        o_pred = self.sigmoid(self.net3)\n",
    "        return o_pred \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        # activation function \n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        #derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def backward(self, X, y, o_pred):\n",
    "        # backward propgate through the network\n",
    "\n",
    "        self.d3 = (y - o_pred) * self.sigmoidPrime(o_pred)\n",
    "        self.d2 = self.d3.dot(self.W3.T) * self.sigmoidPrime(self.fnet2)\n",
    "        self.d1 = self.d2.dot(self.W2.T) * self.sigmoidPrime(self.fnet1)\n",
    "\n",
    "        self.W1 += self.c * np.dot(X.T, self.d1)\n",
    "        self.W2 += self.c * np.dot(self.fnet1.T, self.d2)\n",
    "        self.W3 += self.c * np.dot(self.fnet2.T, self.d3)\n",
    "    def train (self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN = Neural_Network()\n",
    "for i in range(400):\n",
    "    pred = NN.forward(train_input)\n",
    "    pred = pred * (max_out - min_out) + min_out\n",
    "    NN.train(train_input, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: \n",
      "[[ 3.38935206e-05]\n",
      " [-1.44380807e-04]\n",
      " [-1.07131982e-04]\n",
      " [ 1.17032410e-04]\n",
      " [ 3.64568922e-04]\n",
      " [ 2.45137879e-04]\n",
      " [-9.85409599e-05]\n",
      " [-1.78051286e-04]\n",
      " [ 1.08851692e-04]\n",
      " [ 6.33479055e-04]\n",
      " [ 2.51486631e-04]\n",
      " [-2.35431510e-04]\n",
      " [-6.51858875e-04]\n",
      " [-4.47170640e-04]\n",
      " [-4.58291609e-04]\n",
      " [-7.38669228e-04]\n",
      " [-3.17707075e-04]\n",
      " [-1.77675902e-04]\n",
      " [ 1.07938851e-04]\n",
      " [ 2.45672685e-04]\n",
      " [-1.14511803e-04]\n",
      " [-2.47826520e-04]\n",
      " [ 5.04321955e-05]\n",
      " [-1.52382422e-04]\n",
      " [-5.61855533e-04]\n",
      " [-4.34834808e-04]\n",
      " [-3.04861040e-04]\n",
      " [-3.02497557e-04]\n",
      " [-2.89959660e-04]\n",
      " [-3.22167987e-04]]\n",
      "Loss: \n",
      "0.009623421048924139\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = NN.forward(test_input)\n",
    "pred = pred * (max_out - min_out) + min_out\n",
    "print (\"Predicted Output: \\n\" + str(pred)) \n",
    "print (\"Loss: \\n\" + str(np.mean(np.square(test_output - NN.forward(test_input))))) # mean sum squared loss\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
